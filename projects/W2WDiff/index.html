<!DOCTYPE HTML>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

  <title>W2WDiff: Generalizing Underwater Diffusion Model via  Unsupervised Underwater Conversion</title>
  
  <meta name="author" content="Yuanlin Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="../projects.css">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="icon" type="image/png" href="./logo1.png">
</head>

<body style="width: 100%;">
    <div style="width: 100%;">
        <!-- Title -->
        <div class="root-content" style="padding-top: 30px;">
                <img src="./logo1.png" alt="logo" style="max-width: 10%; height: auto;">
            <name>
<!--                <span style="color: rgb(145, 172, 224);">W2WDiff</span>: Generalizing Underwater Diffusion Model via Unsupervised Underwater Conversion-->
                    W2WDiff: Generalizing Underwater Diffusion Model via Unsupervised Underwater Conversion
            </name>
            <br>
            <div id="author-list">
                Yuan-Lin Zhang<sup>1,2,#</sup>&nbsp;&nbsp;&nbsp;
                Jie-Yu Yuan<sup>2,#</sup>&nbsp;&nbsp;&nbsp;
<!--                <a href="https://scholar.google.com/citations?user=RZLYwR0AAAAJ&hl=en">Chun-Le Guo</a><sup>1,*</sup>&nbsp;&nbsp;&nbsp;-->
                Xiao Chen<sup>1,*</sup> &nbsp;&nbsp;&nbsp;
                Xiong-Xin Tang<sup>3,*</sup> &nbsp;&nbsp;
                Qiao Chen<sup>3</sup>&nbsp;&nbsp;&nbsp;
                Yi-Quan Wang<sup>1</sup>&nbsp;&nbsp;&nbsp;
                Chong-Yi Li<sup>2</sup>
<!--                Xun Liu<sup>4</sup>&nbsp;&nbsp;&nbsp;-->
<!--                <a href="https://li-chongyi.github.io/">Chong-Yi Li</a><sup>1,*</sup>&nbsp;&nbsp;&nbsp;-->
            </div>
            <div id="institution-list">
                <sup>1</sup>Minzu University of China&nbsp;&nbsp;&nbsp;
                <sup>2</sup>Nankai University&nbsp;&nbsp;&nbsp;
                <sup>3</sup>Chinese Academy of Sciences
<!--                <sup>3</sup>University of Electronic Science and Technology of China-->
<!--                <sup>4</sup>Beijing Institute of Space Mechanics and Electricity&nbsp;&nbsp;&nbsp;-->
            </div>
            <!-- <p id="publication">
                CVPR 2024
            </p> -->
            <div id="button-list">
                <span class="link-button disabled">
                    <a class="link-button-content", href="", target="_blank">
                        <span>
                            <svg class="svg-inline--fa fa-file-pdf fa-w-12" style=" position: relative; top: 0.15em;" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg>
                        </span>
                        &nbsp;
                        Paper
                    </a>
                </span>
                <!-- <span class="link-button">
                    <a class="link-button-content", href="https://arxiv.org/abs/2401.08123", target="_blank">
                        <span>
                            <svg class="svg-inline--fa fa-file-pdf fa-w-12" style="position: relative; top: 0.15em;" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg>
                        </span>
                        &nbsp;  
                        Supp (More Visual Results)
                    </a>
                </span> -->
                <span class="link-button">
                    <a class="link-button-content" href=" ", target="_blank">
                        <span>
                            <svg class="svg-inline--fa fa-file-pdf" aria-hidden="true" version="1.1" viewBox="0 0 16 16" width="1.2em" style="position: relative; top: 0.25em;"><path fill="currentColor" fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg>
                        </span>
                        &nbsp; 
                        Code (Coming Soon)
                    </a>
                </span>
                <span class="link-button">
                    <a class="link-button-content", href="#bib">
                        <span>
                            <svg class="svg-inline--fa fa-file-pdf" aria-hidden="true" style="position: relative; top: 0.15em;" width="1em" xmlns="http://www.w3.org/2000/svg" fill="currentColor" class="bi bi-bookmarks" viewBox="0 0 16 16"> <path fill="currentColor" fill-rule="evenodd" d="M2 4a2 2 0 0 1 2-2h6a2 2 0 0 1 2 2v11.5a.5.5 0 0 1-.777.416L7 13.101l-4.223 2.815A.5.5 0 0 1 2 15.5V4zm2-1a1 1 0 0 0-1 1v10.566l3.723-2.482a.5.5 0 0 1 .554 0L11 14.566V4a1 1 0 0 0-1-1H4z" fill="white"></path> <path fill="currentColor" fill-rule="evenodd" d="M4.268 1H12a1 1 0 0 1 1 1v11.768l.223.148A.5.5 0 0 0 14 13.5V2a2 2 0 0 0-2-2H6a2 2 0 0 0-1.732 1z" fill="white"></path> </svg>
                        </span>
                        &nbsp;  
                        BibTex
                    </a>
                </span>
            </div>
        </div>


        <!-- Visual Results -->
        <div style="background-color: #f5f5f5; margin-right: auto; margin-left: auto;">
            <div class="root-content" style="padding-top: 10px;">
                <h1 class="section-name">&#128293; A More Generalizable Underwater Enhancement Method &#128293;</h1>
                <p class="section-content-text">
           We propose a novel diffusion-based underwater image enhancement (UIE) framework that integrates water-to-water domain aggregation with latent space operations to achieve superior generalization and enhancement performance. This design effectively addresses critical limitations of existing diffusion-based UIE methods, particularly their susceptibility to distribution shifts and semantic inconsistencies.
To further validate the robustness and applicability of our approach, we present representative enhancement results across six common and challenging degradation scenarios: yellowish haze, greenish casts, light blue attenuation, deep blue absorption, low-light conditions, and fog-like veils.

                </p>
                <table style="border: 0px black solid; margin:auto" >
                    <tbody>
                        <tr>
                            <td style="padding: 5px; width: 300;text-align: left;"><div id="jt1" style="width:300px;text-align:left;"></div></td>
                            <td style="padding: 5px; width: 340;text-align: center;"><div id="jt2" style="width:340px;text-align:center;"></div></td>
                            <td style="padding: 5px; width:340; text-align: right;"><div id="jt3" style="width:340px;text-align:right;"></div></td>
                        </tr>
                    </tbody>
                </table>
                <table style="border: 0px black solid; border-top: 0; margin:auto">
                    <tbody>
                        <tr>
<!--                            <td style="padding: 10px; width:400; text-align: left;"><div id="jt3" style="width:400px;text-align:left;"></div></td>-->
                            <td style="padding: 8px; width:350; text-align: left;"><div id="jt4" style="width:350px;text-align:left;"></div></td>
                            <td style="padding: 8px; width:350; text-align: center;"><div id="jt5" style="width:350px;text-align:center;"></div></td>
                             <td style="padding: 8px; width:260; text-align: right;"><div id="jt6" style="width:260px;text-align:right;"></div></td>
                        </tr>
                    </tbody>
                </table>
<!--                <table style="border: 0px black solid; border-top: 0; margin:auto">-->
<!--                    <tbody>-->
<!--                        <tr>-->
<!--                            <td style="padding: 10px; width:400; text-align: left;"><div id="jt6" style="width:400px;text-align:left;"></div></td>-->
<!--                            <td style="padding: 10px; width:394; text-align: right;"><div id="jt7" style="width:394px;text-align:right;"></div></td>-->
<!--                        </tr>-->
<!--                    </tbody>-->
<!--                </table>-->
            </div>
        </div>
        


        <!-- Paper Information -->
        <div class="root-content" style="padding-top: 30px;">
            <div class="section-content">
            <h1 class="section-name"> Abstract </h1>
                <p class="section-content-text">

                    Underwater optical imaging constitutes a crucial modality for acquiring marine information and plays an indispensable role in a wide range of fields, including ocean engineering, subsea resource exploration,
                    and geoscience and remote sensing. Maintaining consistent performance in supervised underwater image enhancement (UIE) models across
                    diverse real-world scenarios is challenging due to the inherent complexity of underwater environments and the limited availability of
                    diverse datasets. To address this, we propose a novel UIE framework that adaptively and training-free transforms complex underwater
                    images into more manageable known degraded images. This process effectively preserves the semantic content of the input images. Subsequently, we employ diffusion to transition from the known degraded domain distribution to the target reference domain distribution,
                    thereby achieving effective and consistent enhancement across various underwater scenarios. To ensure the efficacy and flexibility of the
                    diffusion process, our approach operates in latent space rather than pixel space,
                    utilizing a novel Markov chain specifically tailored for underwater scenes. This method not only reduces the numerous sampling steps but also minimizes color shifts during the sampling process.
                    Furthermore, we introduce a Content Consistency Module (CCM) to improve structural consistency. Experimental results demonstrate that <b>W2WDiff</b> outperforms state-ofthe-art methods,
                    exhibiting robust zero-shot generalization capabilities.

                </p>
            </div>

            <div style="padding-top: 20px;">
                <h1 class="section-name">Motivation</h1>
                <img src="teaser.png" width="600"/>
                <p class="section-content-text">
                    Comparison between Previous Diffusion-Based UIE Models and Our <b>W2WDiff</b> Framework.
                    (a) General diffusion-based UIE models directly learn a supervised mapping from the underwater degradation domain <var> D </var> to the reference domain <var> R </var>,
                    often struggling with domain shifts across different datasets. (b) Our proposed <b>W2WDiff </b> framework
                    introduces an unsupervised <i>water-to-water transformation</i>, which first maps the original underwater domain <var> D </var> to an intermediate,
                    more tractable underwater domain <var> D' </var>. This common underwater space bridges the distribution gap between diverse training and testing datasets,
                    ensuring more effective adaptation. A diffusion model is then employed to reconstruct the reference domain <var> R </var> from <var> D' </var>.
                    By leveraging this intermediate transformation, our approach mitigates domain mismatches and
                    enhances zero-shot generalization across various underwater environments.
                </p>
            </div>

            <div style="padding-top: 20px;">
                <h1 class="section-name">
                    More Visual Comparisons
                </h1>
                 <p class="section-content-text">

                  In this section, we present additional qualitative results that could not be included in the main paper due to space limitations.
                     Specifically, visualizations on the out-of-distribution EUVP , U45 and UCCS datasets demonstrate the strong generalization capability of our method.
                     Moreover, comparisons on the more challenging C60 dataset reveal that our approach consistently yields superior visual results compared to existing methods.
<!--                     These findings further validate the robustness and effectiveness of our approach across diverse and challenging underwater imaging conditions.-->

                </p>
<!--                <img src="vis_1.png" width="1000"/>-->
<!--                <img src="line.png" width="700"/><br><br>-->
<!--                <img src="vis_2.png" width="1000"/>-->
<!--                <img src="line.png" width="700"/><br><br>-->
<!--                <img src="vis_3.png" width="1000"/>-->
<!--                <img src="line.png" width="700"/><br><br>-->
<!--                <img src="vis_4.png" width="1000"/>-->
<!--                &lt;!&ndash; <img src="result2.png" width="998" style="margin-top: -4px;"/> &ndash;&gt;-->
                   <figure>
                    <img src="vis_1.png" width="1000"/>
                       <figcaption style="text-align: left;"> <b>Visual comparisons on the challenging C60 dataset.</b> Our method achieves superior visual enhancement under extremely adverse conditions, including low-light environments, compound degradation types, and turbid water. The results demonstrate robust detail preservation and effective color correction, validating the method  capability in real-world, high-complexity underwater scenarios.</figcaption>
                </figure>
                <img src="line.png" width="700"/><br><br>

                <figure>
                    <img src="vis_2.png" width="1000"/>
                    <figcaption style="text-align: left;"><b>Generalization performance on out-of-distribution datasets EUVP and U45.</b> Compared with baseline and diffusion-based methods, our approach exhibits strong generalization and robustness across diverse domains. It effectively enhances distant regions, seabed textures,
                        and areas with scattered sediments, features typically overlooked by existing methods, demonstrating its adaptability to varying underwater distributions.</figcaption>
                </figure>
                <img src="line.png" width="700"/><br><br>

                <figure>
                    <img src="vis_3.png" width="1000"/>
                    <figcaption></figcaption>
                </figure>
                <img src="line.png" width="700"/><br><br>

                <figure>
                    <img src="vis_4.png" width="1000"/>
                    <figcaption style="text-align: left;"><b>Enhancement consistency on the UCCS dataset.</b> Our method maintains consistent enhancement across frames,
                        addressing the stochasticity and semantic instability commonly observed in diffusion-based UIE methods.
                        This consistency is particularly critical for video-based applications,
                        underscoring the reliability and temporal stability of our framework.</figcaption>
                </figure>

            </div>
<!--                       <div style="padding-top: 20px;">-->
<!--                <h1 class="section-name">-->
<!--                    Quantitative Comparison-->
<!--                </h1>-->
<!--                <img src="vis_1.png" width="1000"/>-->
<!--                <img src="line.png" width="700"/><br><br>-->
<!--                <img src="vis_2.png" width="1000"/>-->
<!--&lt;!&ndash;                <img src="line.png" width="700"/><br><br>&ndash;&gt;-->
<!--&lt;!&ndash;                <img src="result3.png" width="1000"/>&ndash;&gt;-->
<!--                &lt;!&ndash; <img src="result2.png" width="998" style="margin-top: -4px;"/> &ndash;&gt;-->
<!--            </div>-->

<!--            <div>-->
<!--                <h1 class="section-name" style="margin-top: 30px; text-align: left; font-size: 25px;">-->
<!--                    BibTex-->
<!--                </h1>-->
<!--                <a name="bib"></a>-->
<!--                <pre style="margin-top: 5px;" class="bibtex">-->
<!--                    <code>-->

<!--&lt;!&ndash;@article{jiang2024the,&ndash;&gt;-->
<!--&lt;!&ndash;        title={The Devil is in the Details: Boosting Guided Depth Super-Resolution via Rethinking Cross-Modal Alignment and Aggregation},&ndash;&gt;-->
<!--&lt;!&ndash;        author={Jiang, Xinni and Kuang, Zengsheng and Guo, Chunle and Zhang, Ruixun and Lei Cai and Xiao Fan and Li, Chongyi},&ndash;&gt;-->
<!--&lt;!&ndash;        journal={arXiv preprint arXiv:2401.08123},&ndash;&gt;-->
<!--&lt;!&ndash;        year={2024}&ndash;&gt;-->
<!--&lt;!&ndash;}&ndash;&gt;-->

<!--</code></pre>-->
<!--            </div>-->

            <div style="margin-bottom: 50px;">
                <h1 class="section-name" style="margin-top: 30px; margin-bottom: 10px; text-align: left; font-size: 25px;">
                    Contact
                </h1>
                <p class="section-content-text">
                    Feel free to contact us at <strong>zason_zyl@163.com</strong>
                </p>
            </div>
        </div>


        <!-- <div style="background-color: #f5f5f5; margin-right: auto; margin-left: auto; text-align: center; padding-top: 35px; padding-bottom: 35px;">
            <a href="https://www.freecounterstat.com" title="web page counter"><img src="https://counter4.optistats.ovh/private/freecounterstat.php?c=xdafgsksdt68ssg1n7kfmr61ul4ugbb6" border="0" title="web page counter" alt="web page counter"></a>
            <p>Visitor Count</p>
        </div> -->
        <div style="background-color: #f5f5f5; margin-right: auto; margin-left: auto; text-align: center; padding-top: 35px; padding-bottom: 35px;">
            <p><font face="Arial"> &copy; Yuan-Lin Zhang | Last updated: April. 2025</font></p>
        </div>
    </div>
</body>



<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$']]},
        messageStyle: "none"
    });
</script>



<!-- juxtapose_images -->
<script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>
<link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">

<script>
    slider = new juxtapose.JXSlider('#jt1',
        [
            {src: 'juxtapose_images/1_left_uie.png'},
            {src: 'juxtapose_images/1_right_uie.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>
<script>
    slider = new juxtapose.JXSlider('#jt2',
        [
            {src: 'juxtapose_images/3_left_uie.png'},
            {src: 'juxtapose_images/3_right_uie.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>
<script>
    slider = new juxtapose.JXSlider('#jt3',
        [
            {src: 'juxtapose_images/2_left_uie.png'},
            {src: 'juxtapose_images/2_right_uie.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>
<script>
    slider = new juxtapose.JXSlider('#jt4',
        [
            {src: 'juxtapose_images/4_left_uie.png'},
            {src: 'juxtapose_images/4_right_uie.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>
<script>
    slider = new juxtapose.JXSlider('#jt5',
        [
            {src: 'juxtapose_images/5_left_uie.png'},
            {src: 'juxtapose_images/5_right_uie.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>
<script>
    slider = new juxtapose.JXSlider('#jt6',
        [
            {src: 'juxtapose_images/6_left_uie.png'},
            {src: 'juxtapose_images/6_right_uie.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>
<script>
    slider = new juxtapose.JXSlider('#jt7',
        [
            {src: 'juxtapose_images/7_left.png'},
            {src: 'juxtapose_images/7_right.png'}
        ],
        {
            animate: true,
            showLabels: false,
            showCredits: false,
            startingPosition: "50%",
            makeResponsive: true
        });
</script>




